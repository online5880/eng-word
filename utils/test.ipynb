{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Grammar Score: 0.74\n",
      "Grammar score below threshold, attempting correction with Grammarformer.\n",
      "Updated Grammar Score: 0.99\n",
      "Initial Coherence Score: 1\n",
      "Final Sentence: He has one car.\n",
      "Final Grammar Score: 0.99\n",
      "Final Coherence Score: 1\n"
     ]
    }
   ],
   "source": [
    "from utils.Pipeline.grammar_score import AdvancedGrammarScorer  # 문법 검사 클래스\n",
    "from utils.Pipeline.consistency import measure_sc  # 의미 일관성 검사 함수\n",
    "from utils.Pipeline.grammar_corrector import (\n",
    "    GrammarCorrector,\n",
    ")  # Grammarformer를 사용한 문장 보완 클래스\n",
    "\n",
    "\n",
    "class SentenceEvaluationPipeline:\n",
    "    def __init__(self, grammar_threshold: float = 0.9, coherence_threshold: int = 1):\n",
    "        self.grammar_scorer = AdvancedGrammarScorer()  # 문법 점수 측정\n",
    "        self.coherence_checker = measure_sc  # 의미 일관성 점검 함수\n",
    "        self.grammar_threshold = grammar_threshold  # 문법 점수 기준\n",
    "        self.coherence_threshold = coherence_threshold  # 일관성 기준\n",
    "        self.grammar_corrector = GrammarCorrector()  # GrammarCorrector 초기화\n",
    "\n",
    "    def evaluate_and_correct(self, sentence: str):\n",
    "        # 1. 문법 점수 계산\n",
    "        grammar_score, grammar_details = self.grammar_scorer.score_sentence(sentence)\n",
    "        print(f\"Initial Grammar Score: {grammar_score}\")\n",
    "\n",
    "        # 2. 문법 점수 기준 충족 여부 확인\n",
    "        if grammar_score < self.grammar_threshold:\n",
    "            print(\n",
    "                \"Grammar score below threshold, attempting correction with Grammarformer.\"\n",
    "            )\n",
    "            sentence = self.grammar_corrector.correct_sentence(\n",
    "                sentence\n",
    "            )  # GrammarCorrector로 교정\n",
    "            grammar_score, _ = self.grammar_scorer.score_sentence(\n",
    "                sentence\n",
    "            )  # 수정 후 다시 점검\n",
    "            print(f\"Updated Grammar Score: {grammar_score}\")\n",
    "\n",
    "        # 3. 의미 일관성 점검\n",
    "        coherence_score = self.coherence_checker(sentence)\n",
    "        print(f\"Initial Coherence Score: {coherence_score}\")\n",
    "\n",
    "        # 4. 의미 일관성 기준 충족 여부 확인\n",
    "        if coherence_score < self.coherence_threshold:\n",
    "            print(\"Coherence score below threshold, attempting further correction.\")\n",
    "            sentence = self.grammar_corrector.correct_sentence(\n",
    "                sentence\n",
    "            )  # GrammarCorrector로 보완\n",
    "            coherence_score = self.coherence_checker(sentence)  # 수정 후 다시 점검\n",
    "            print(f\"Updated Coherence Score: {coherence_score}\")\n",
    "\n",
    "        # 최종 결과 반환\n",
    "        return {\n",
    "            \"final_sentence\": sentence,\n",
    "            \"grammar_score\": grammar_score,\n",
    "            \"coherence_score\": coherence_score,\n",
    "        }\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = SentenceEvaluationPipeline()\n",
    "    input_sentence = \"He have one cars.\"\n",
    "    result = pipeline.evaluate_and_correct(input_sentence)\n",
    "\n",
    "    print(\"Final Sentence:\", result[\"final_sentence\"])\n",
    "    print(\"Final Grammar Score:\", result[\"grammar_score\"])\n",
    "    print(\"Final Coherence Score:\", result[\"coherence_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검사문장: 'I have an aunt who lives nearby.' 학습단어: 'aunt'\n",
      "Initial Grammar Score: 1.01\n",
      "Initial Coherence Score: 1\n",
      "검사문장: 'I’m going to the concert hall.' 학습단어: 'be going to'\n",
      "Initial Grammar Score: 0.98\n",
      "Initial Coherence Score: 1\n",
      "검사문장: 'I scanned the boy.' 학습단어: 'boy'\n",
      "Initial Grammar Score: 0.98\n",
      "Initial Coherence Score: 1\n",
      "검사문장: 'I exercise every morning to stay healthy.' 학습단어: 'exercise'\n",
      "Initial Grammar Score: 0.99\n",
      "Initial Coherence Score: 1\n",
      "검사문장: 'I know The girl is my sister and this is my doll.' 학습단어: 'girl'\n",
      "Initial Grammar Score: 0.9\n",
      "Initial Coherence Score: 0\n",
      "Coherence score below threshold, attempting further correction.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 72\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# 파일 경로 설정 및 실행\u001b[39;00m\n\u001b[0;32m     71\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/user/Desktop/eng-word/utils/Grammar_Score/grammar_sentences.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mprocess_all_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 58\u001b[0m, in \u001b[0;36mprocess_all_sentences\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# 파이프라인 평가 및 수정\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m검사문장: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 학습단어: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_and_correct\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m word  \u001b[38;5;66;03m# 단어 정보 추가\u001b[39;00m\n\u001b[0;32m     60\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m, in \u001b[0;36mSentenceEvaluationPipeline.evaluate_and_correct\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coherence_score \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence_threshold:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoherence score below threshold, attempting further correction.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrammar_corrector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# GrammarCorrector로 보완\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     coherence_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence_checker(sentence)  \u001b[38;5;66;03m# 수정 후 다시 점검\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated Coherence Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoherence_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\eng-word\\utils\\Pipeline\\grammar_corrector.py:12\u001b[0m, in \u001b[0;36mGrammarCorrector.correct_sentence\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrect_sentence\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Grammarformer를 사용하여 문장 교정\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(sentence, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     13\u001b[0m     corrected_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m corrected_sentence\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\transformers\\generation\\utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2212\u001b[0m     )\n\u001b[0;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2216\u001b[0m         input_ids,\n\u001b[0;32m   2217\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2218\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2219\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2220\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2221\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2222\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2223\u001b[0m     )\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2235\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\transformers\\generation\\utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3210\u001b[0m     outputs,\n\u001b[0;32m   3211\u001b[0m     model_kwargs,\n\u001b[0;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3213\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1920\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_word_embeddings:\n\u001b[0;32m   1916\u001b[0m     \u001b[38;5;66;03m# Rescale output before projecting on vocab\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;66;03m# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\u001b[39;00m\n\u001b[0;32m   1918\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m sequence_output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m-> 1920\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1922\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Pipeline.grammar_score import AdvancedGrammarScorer  # 문법 검사 클래스\n",
    "from Pipeline.consistency import measure_sc  # 의미 일관성 검사 함수\n",
    "from Pipeline.grammar_corrector import GrammarCorrector  # Grammarformer를 사용한 문장 보완 클래스\n",
    "\n",
    "class SentenceEvaluationPipeline:\n",
    "    def __init__(self, grammar_threshold: float = 0.7, coherence_threshold: int = 1):\n",
    "        self.grammar_scorer = AdvancedGrammarScorer()  # 문법 점수 측정\n",
    "        self.coherence_checker = measure_sc  # 의미 일관성 점검 함수\n",
    "        self.grammar_threshold = grammar_threshold  # 문법 점수 기준\n",
    "        self.coherence_threshold = coherence_threshold  # 일관성 기준\n",
    "        self.grammar_corrector = GrammarCorrector()  # GrammarCorrector 초기화\n",
    "\n",
    "    def evaluate_and_correct(self, sentence: str):\n",
    "        # 1. 문법 점수 계산\n",
    "        grammar_score, grammar_details = self.grammar_scorer.score_sentence(sentence)\n",
    "        print(f\"Initial Grammar Score: {grammar_score}\")\n",
    "        \n",
    "        # 2. 문법 점수 기준 충족 여부 확인\n",
    "        if grammar_score < self.grammar_threshold:\n",
    "            print(\"Grammar score below threshold, attempting correction with Grammarformer.\")\n",
    "            sentence = self.grammar_corrector.correct_sentence(sentence)  # GrammarCorrector로 교정\n",
    "            grammar_score, _ = self.grammar_scorer.score_sentence(sentence)  # 수정 후 다시 점검\n",
    "            print(f\"Updated Grammar Score: {grammar_score}\")\n",
    "        \n",
    "        # 3. 의미 일관성 점검\n",
    "        coherence_score = self.coherence_checker(sentence)\n",
    "        print(f\"Initial Coherence Score: {coherence_score}\")\n",
    "        \n",
    "        # 4. 의미 일관성 기준 충족 여부 확인\n",
    "        if coherence_score < self.coherence_threshold:\n",
    "            print(\"Coherence score below threshold, attempting further correction.\")\n",
    "            sentence = self.grammar_corrector.correct_sentence(sentence)  # GrammarCorrector로 보완\n",
    "            coherence_score = self.coherence_checker(sentence)  # 수정 후 다시 점검\n",
    "            print(f\"Updated Coherence Score: {coherence_score}\")\n",
    "        \n",
    "        # 최종 결과 반환\n",
    "        return {\n",
    "            \"final_sentence\": sentence,\n",
    "            \"grammar_score\": grammar_score,\n",
    "            \"coherence_score\": coherence_score\n",
    "        }\n",
    "\n",
    "# 파일에서 데이터 로드 및 처리\n",
    "def process_all_sentences(file_path: str):\n",
    "    # CSV 파일 로드\n",
    "    df = pd.read_csv(file_path)\n",
    "    pipeline = SentenceEvaluationPipeline()\n",
    "\n",
    "    # 모든 문장에 대해 파이프라인 실행\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        sentence = row['문장']\n",
    "        word = row['포함된 단어']\n",
    "        \n",
    "        # 파이프라인 평가 및 수정\n",
    "        print(f\"검사문장: '{sentence}' 학습단어: '{word}'\")\n",
    "        result = pipeline.evaluate_and_correct(sentence)\n",
    "        result[\"word\"] = word  # 단어 정보 추가\n",
    "        results.append(result)\n",
    "\n",
    "    # 결과 출력\n",
    "    for res in results:\n",
    "        print(\"\\nProcessed Result:\")\n",
    "        print(\"Word:\", res[\"word\"])\n",
    "        print(\"Final Sentence:\", res[\"final_sentence\"])\n",
    "        print(\"Final Grammar Score:\", res[\"grammar_score\"])\n",
    "        print(\"Final Coherence Score:\", res[\"coherence_score\"])\n",
    "\n",
    "# 파일 경로 설정 및 실행\n",
    "file_path = 'C:/Users/user/Desktop/eng-word/utils/Grammar_Score/grammar_sentences.csv'\n",
    "process_all_sentences(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/user/Desktop/eng-word/utils/Grammar_Score/grammar_sentences.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/user/Desktop/eng-word/utils/Grammar_Score/grammar_sentences.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
