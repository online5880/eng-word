{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qwen2_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqwen2_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Qwen2LLM\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'qwen2_model'"
     ]
    }
   ],
   "source": [
    "from qwen2_model import Qwen2LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: She go to the store yesterday.\n",
      "Corrected Sentence: She went to the store yesterday.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "class GrammarCorrector:\n",
    "    def __init__(self):\n",
    "        # Grammarformer 모델과 토크나이저 초기화\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"prithivida/grammar_error_correcter_v1\")\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(\"prithivida/grammar_error_correcter_v1\")\n",
    "\n",
    "    def correct_sentence(self, sentence: str) -> str:\n",
    "        # Grammarformer를 사용하여 문장 교정\n",
    "        inputs = self.tokenizer(sentence, return_tensors=\"pt\")\n",
    "        outputs = self.model.generate(**inputs, max_length=50)\n",
    "        corrected_sentence = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return corrected_sentence\n",
    "\n",
    "# 사용 예시\n",
    "corrector = GrammarCorrector()\n",
    "input_sentence = \"She go to the store yesterday.\"\n",
    "\n",
    "corrected_sentence = corrector.correct_sentence(input_sentence)\n",
    "print(\"Original Sentence:\", input_sentence)\n",
    "print(\"Corrected Sentence:\", corrected_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from your_grammar_module import GrammarChecker  # 문법 검사 모듈\n",
    "# from your_coherence_module import CoherenceScorer  # 의미 일관성 점수 모듈\n",
    "\n",
    "# 모델과 토크나이저 초기화\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "input_sentence = \"This is a example sentence that might have grammar or coherence issues.\"\n",
    "\n",
    "\n",
    "# Qwen2 모델을 통해 문장을 수정\n",
    "prompt = f\"Please rewrite the following sentence to be grammatically correct and coherent: '{input_sentence}'\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "corrected_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Corrected Sentence:\", corrected_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from your_grammar_module import GrammarChecker  # 문법 검사 모듈\n",
    "# from your_coherence_module import CoherenceScorer  # 의미 일관성 점수 모듈\n",
    "\n",
    "# 모델과 토크나이저 초기화\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-7B-Instruct\")\n",
    "\n",
    "# grammar_checker = GrammarChecker()\n",
    "# coherence_scorer = CoherenceScorer()\n",
    "\n",
    "def correct_sentence_with_qwen(sentence, coherence_threshold=0.8):\n",
    "    # 문법 검사 및 초기 수정\n",
    "    corrected_sentence = grammar_checker.correct(sentence)\n",
    "    coherence_score = coherence_scorer.score(corrected_sentence)\n",
    "\n",
    "    # 의미 일관성 기준 이하일 경우 모델을 통해 수정 반복\n",
    "    attempts = 0\n",
    "    max_attempts = 3\n",
    "    while coherence_score < coherence_threshold and attempts < max_attempts:\n",
    "        print(f\"Attempt {attempts + 1}: Low coherence detected - Rewriting sentence with Qwen2\")\n",
    "\n",
    "        # Qwen2 모델을 통해 문장을 다시 작성\n",
    "        prompt = f\"Please rewrite the following sentence to be grammatically correct and coherent: '{corrected_sentence}'\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs)\n",
    "        corrected_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # 다시 문법 검사 및 일관성 점검\n",
    "        corrected_sentence = grammar_checker.correct(corrected_sentence)\n",
    "        coherence_score = coherence_scorer.score(corrected_sentence)\n",
    "        attempts += 1\n",
    "\n",
    "    # 최종 수정된 문장 반환\n",
    "    return corrected_sentence\n",
    "\n",
    "# 사용 예시\n",
    "input_sentence = \"This is a example sentence that might have grammar or coherence issues.\"\n",
    "final_sentence = correct_sentence_with_qwen(input_sentence)\n",
    "print(\"Final corrected sentence:\", final_sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
