{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일관성 점수 코드 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"문장\": [\n",
    "        \"She go to the store yesterday.\",\n",
    "        \"They enjoys watching movies.\",\n",
    "        \"This is a perfect example of the method.\",\n",
    "        \"He walk to school every day.\",\n",
    "        \"The cat is chasing it tail.\"\n",
    "    ],\n",
    "    \"포함된 단어\": [\"go\", \"movies\", \"example\", \"walk\", \"cat\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"test_data.csv\", index=False, encoding='cp949')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (4.45.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 10.0/10.0 MB 88.8 MB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.2\n",
      "    Uninstalling transformers-4.45.2:\n",
      "      Successfully uninstalled transformers-4.45.2\n",
      "Successfully installed transformers-4.46.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 5/5 [03:00<00:00, 36.07s/it]\n",
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"Qwen/Qwen2-VL-7B-Instruct\"  # 모델 이름\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# 의미 일관성 점수 측정 함수\n",
    "def measure_semantic_coherence(sentence):\n",
    "    prompt = f\"Rate the semantic coherence of the following sentence on a scale from 0 to 1:\\n\\n'{sentence}'\\n\\nScore:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # 텍스트 인코딩 및 점수 계산 예시\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 의미 일관성 점수 (예: 출력 벡터의 평균값을 사용)\n",
    "    coherence_score = float(outputs.last_hidden_state.mean().item())\n",
    "    return coherence_score\n",
    "\n",
    "\n",
    "# 예시 문장\n",
    "sentences = [\n",
    "    \"The cat is sleeping on the bed.\",\n",
    "    \"She go to the store yesterday.\",\n",
    "    \"asdfasdfasdfasdfasdfasdfasdf\",\n",
    "]\n",
    "\n",
    "# 각 문장에 대해 의미 일관성 점수 계산\n",
    "for sentence in sentences:\n",
    "    score = measure_semantic_coherence(sentence)\n",
    "    print(f\"문장: {sentence}\\n의미 일관성 점수: {score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response: 1\n",
      "Sentence: The dog barks loudly at night.\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Model Response: 1\n",
      "Sentence: She went to the store to buy some milk.\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Model Response: 1\n",
      "Sentence: The sun is very bright today.\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Model Response: 1\n",
      "Sentence: He reads a book every evening before bed.\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Model Response: 1\n",
      "Sentence: The students are working on their project together.\n",
      "True Label: 1, Predicted Label: 1\n",
      "\n",
      "Model Response: 1\n",
      "Sentence: The apple sings softly to the wind.\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Model Response: 0\n",
      "Sentence: She quickly swims through the library shelves.\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Model Response: 1\n",
      "Sentence: The car danced across the road.\n",
      "True Label: 0, Predicted Label: 1\n",
      "\n",
      "Model Response: 0\n",
      "Sentence: They painted the silence with laughter.\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Model Response: 0\n",
      "Sentence: The sky ate all the music at sunset.\n",
      "True Label: 0, Predicted Label: 0\n",
      "\n",
      "Model Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# FLAN-T5 모델 로드\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# 의미 일관성 및 문법 평가 함수\n",
    "def measure_semantic_coherence(sentence):\n",
    "    # 구체적인 평가 프롬프트 생성\n",
    "    prompt = (\n",
    "        f\"Evaluate the following sentence for both grammatical correctness and semantic coherence. \"\n",
    "        f\"Answer only '1' if the sentence is both grammatically correct and semantically coherent. \"\n",
    "        f\"Answer only '0' if the sentence has grammatical errors or lacks coherence.\\n\\n\"\n",
    "        f\"Sentence: '{sentence}'\\n\\nAnswer with '1' or '0' only:\\n\\nScore:\"\n",
    "    )\n",
    "\n",
    "    # 모델 입력 준비\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # 모델 예측 생성\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=20)  # max_length를 20으로 늘림\n",
    "\n",
    "    # 예측에서 점수 추출\n",
    "    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"Model Response: {response_text}\")  # 디버깅을 위해 모델 응답 출력\n",
    "    try:\n",
    "        # 응답에서 숫자만 추출\n",
    "        coherence_score = float(response_text.strip())\n",
    "    except ValueError:\n",
    "        coherence_score = None  # 잘못된 출력일 경우 처리\n",
    "\n",
    "    return coherence_score\n",
    "\n",
    "\n",
    "# 의미 일관성이 높은 문장과 낮은 문장 예시 (실제 라벨 포함)\n",
    "data = [\n",
    "    # (문장, 실제 라벨)\n",
    "    (\"The dog barks loudly at night.\", 1),\n",
    "    (\"She went to the store to buy some milk.\", 1),\n",
    "    (\"The sun is very bright today.\", 1),\n",
    "    (\"He reads a book every evening before bed.\", 1),\n",
    "    (\"The students are working on their project together.\", 1),\n",
    "    (\"The apple sings softly to the wind.\", 0),\n",
    "    (\"She quickly swims through the library shelves.\", 0),\n",
    "    (\"The car danced across the road.\", 0),\n",
    "    (\"They painted the silence with laughter.\", 0),\n",
    "    (\"The sky ate all the music at sunset.\", 0),\n",
    "]\n",
    "\n",
    "# 예측과 실제 라벨 비교\n",
    "correct_predictions = 0\n",
    "total_predictions = len(data)\n",
    "\n",
    "for sentence, true_label in data:\n",
    "    predicted_score = measure_semantic_coherence(sentence)\n",
    "    # 예측 점수를 이진 라벨로 변환 (1.0이면 1, 그 외는 0)\n",
    "    predicted_label = 1 if predicted_score == 1.0 else 0\n",
    "\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"True Label: {true_label}, Predicted Label: {predicted_label}\\n\")\n",
    "\n",
    "    # 정확도 계산\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
